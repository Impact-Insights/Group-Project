{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 02 Project: Data Cleaning and Preprocessing\n",
    "\n",
    " \n",
    "Topics: \n",
    "1) Understanding messy data and the need for data cleaning \n",
    "2) Handling missing values, duplicates, and outliers \n",
    "3) Data transformation: normalization and standardization \n",
    "4) Using Pandas and NumPy for data preprocessing \n",
    "5) Introduction to Regular Expressions for text cleaning \n",
    "Python Project: \"Data Cleaning Challenge\" â€“ Given a messy dataset, clean it by: Removing missing values Standardizing formats Identifying and handling outliers Dataset: Attached is a csv file with missing values and inconsistent formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Requirements and Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messy_data = pd.read_csv('https://raw.githubusercontent.com/Impact-Insights/Group-Project/refs/heads/main/DMD%20Data%20Group%201%20W_02%20Submission/messy_dataset.csv?token=GHSAT0AAAAAAC6XVLETHM7AG6PH4UJMGHLUZ5YHIOA')\n",
    "messy_data = pd.read_csv('messy_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the information provided above we can immediately notice that there are some issues that can be fixed:\n",
    "\n",
    "1. We can change the `ID` column data format to be an `object` as we are not going to perform any calculations on it.\n",
    "2. We can notice that there are 7 missing values in the `Age` column because it counts that there are 36 non-null values while there should be 45 and the data format can be changed to an integer as age is recorded as a whole number and we can perform calculations on it.\n",
    "- We can fill the NaN values in the `Age` column by the column mean which is more suitable as the data indicates that most of the people are in the same age group. \n",
    "3. The `Salary` column can be changed to be of currency data format or just a number as we can perform calculations on it.\n",
    "4. The `Joining` column can be changed to a date-time data format as it is a date type.\n",
    "5. Checking from the `messy_data.head()` results we can observe inconsistencies in the formating style of text, dates and numbers in all the column. We can standarrdize and normalize the data to have a well formatted dataset.\n",
    "6. Since we are having the `ID` column and knowing that it is a unique identifier we should not get any dupliate values.\n",
    "7. The `Email` column should also have unique entries since no more than one person can own the same email address. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Understanding Messy Data and the Need for Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Handling Missing Values, Duplicates, and Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with missing values (Filling with Mean Value) [Age Column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data['Age'] = messy_data['Age'].fillna(0)\n",
    "#messy_data['Age'] = messy_data['Age'].fillna(messy_data['Age'].mean())\n",
    "\n",
    "for column in messy_data.columns:\n",
    "    messy_data['Age'] = np.where(messy_data['Age'] == 0, messy_data['Age'].mean(), messy_data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#messy_data['Age'] = messy_data['Age'].astype('Int64')\n",
    "messy_data['Age'] = round(pd.to_numeric(messy_data['Age'], downcast='integer', errors='coerce'), 0) #errors='coerce' will turn non-numeric values to NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data['Age'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Duplicates and Missing Data [Email Column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data['Email'] = messy_data['Email'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data = messy_data.dropna()\n",
    "messy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Transformation: Normalization and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with the Email Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data.loc[0, 'Email'] = \"eve@example.com\"\n",
    "messy_data.loc[3, 'Email'] = \"david@example.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data['Email'] = messy_data['Email'].str.lower()\n",
    "messy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with the Salary ($) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data.loc[:, 'Salary ($)'] = messy_data['Salary ($)'].str.strip(',.$')\n",
    "messy_data.loc[:, 'Salary ($)'] = messy_data['Salary ($)'].str.replace(',', \"\")\n",
    "\n",
    "messy_data['Salary ($)'] = messy_data['Salary ($)'].astype('float64')\n",
    "\n",
    "messy_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with the Joining Date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data.loc[:, 'Joining Date'] = messy_data.loc[:,'Joining Date'].str.replace('-', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data.loc[:4, 'Joining Date'] = messy_data.loc[:,'Joining Date'].str.replace('-', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORKING THROUGH THE JOINING DATE COLUMN\n",
    "\n",
    " \n",
    "messy_data.at[0, 'Joining Date'] = pd.to_datetime(messy_data.at[0, 'Joining Date'], format='%d/%m/%Y').strftime('%d-%m-%Y')\n",
    "messy_data.at[1, 'Joining Date'] = pd.to_datetime(messy_data.at[1, 'Joining Date'], format='%Y%m%d').strftime('%d-%m-%Y')\n",
    "messy_data.at[2, 'Joining Date'] = pd.to_datetime(messy_data.at[2, 'Joining Date'], format='%d%m%Y').strftime('%d-%m-%Y')\n",
    "messy_data.at[3, 'Joining Date'] = pd.to_datetime(messy_data.at[3, 'Joining Date'], format='%Y%m%d').strftime('%d-%m-%Y')\n",
    "messy_data.at[7, 'Joining Date'] = pd.to_datetime(messy_data.at[7, 'Joining Date'], format='%B %d, %Y').strftime('%d-%m-%Y')\n",
    " \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data['Age'] = messy_data['Age'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_data.sort_values(by='ID', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = messy_data.to_csv('cleaned_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
